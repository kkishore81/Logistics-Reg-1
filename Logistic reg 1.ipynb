{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e8f84-ecfe-4c0f-a5d3-c5bec3416fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. Explain the difference between linear regression and logistic regression models. Provide an example of\n",
    "#a scenario where logistic regression would be more appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f971bf6e-a519-4e79-b993-9ca7ee99f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression is used for predicting continuous numeric values, while logistic regression is used for binary classification tasks and multi class classification, \n",
    "#where the output is a probability between 0 and 1. For example, linear regression can predict house prices based on features like square footage, \n",
    "#while logistic regression can predict whether an email is spam (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15753e9-6245-4d3a-9b26-e49966425630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. What is the cost function used in logistic regression, and how is it optimized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb21fc-de0c-4d17-b620-8de6fdc96eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In logistic regression, the cost function is the logistic loss (log loss) or cross-entropy loss. It measures the dissimilarity between predicted probabilities and actual labels. \n",
    "#Optimization is typically done using gradient descent to minimize this cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1511550e-ef12-4d81-ac13-4ac9d59cdd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. Explain the concept of regularization in logistic regression and how it helps prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a8c842-3cc9-4b39-8fae-f591737d0c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularization in logistic regression adds penalty terms to the cost function to prevent overfitting. L1 regularization (Lasso) encourages sparse feature selection, \n",
    "#while L2 regularization (Ridge) penalizes large coefficient values. Both help control model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d593fbf-1ba7-4406-936e-2234dc5629a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. What is the ROC curve, and how is it used to evaluate the performance of the logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb91c16c-8a5f-4f0e-99c4-2042939e4fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Receiver Operating Characteristic (ROC) curve is used to evaluate the performance of logistic regression. It plots the true positive rate (sensitivity) \n",
    "#against the false positive rate (1-specificity) at various probability thresholds. A larger area under the ROC curve (AUC) indicates better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a433f178-0184-4a4a-b53f-40c4c72b14ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. What are some common techniques for feature selection in logistic regression? How do these techniques help improve the model's performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9334e8-77c1-442b-9afb-53af57b67c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common feature selection techniques for logistic regression include Recursive Feature Elimination (RFE), feature importance from tree-based models, and correlation analysis. \n",
    "#These techniques help improve model performance by removing irrelevant or redundant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb38b951-ca7f-4498-893f-e0df981afed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. How can you handle imbalanced datasets in logistic regression? What are some strategies for dealing with class imbalance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e48711-2014-4beb-98b4-d8b6ad56882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling imbalanced datasets in logistic regression can involve techniques like resampling (oversampling the minority class or undersampling the majority class),\n",
    "#using different evaluation metrics (e.g., F1-score), or using synthetic data generation methods like SMOTE (Synthetic Minority Over-sampling Technique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b150180d-b2ee-462e-bf2d-027b3bd588be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. Can you discuss some common issues and challenges that may arise when implementing logistic\n",
    "#regression, and how they can be addressed? For example, what can be done if there is multicollinearity\n",
    "#among the independent variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc34ea-28ec-4aa7-8d42-4f17b3aa3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common logistic regression challenges include multicollinearity among independent variables, which can be addressed by removing or \n",
    "#combining correlated features or using regularization techniques. Other issues may include outliers, which can be handled through robust techniques,\n",
    "#and model interpretation, which can be improved with feature engineering and visualization tools like Partial Dependence Plots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
